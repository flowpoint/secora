hostname: localhost
port: 42855

num_gpus: 'auto'

name: 'cluster_run_name'

batch_size: 16
infer_batch_size: 16

seed: 42
epochs: 1
shards: 20

grad_accum: 64 # counted in batches

warmup_batches: 10000
temp: 0.05

embedding_size: 128
top_k:  10

logdir: "../cluster_output"
checkpoint_dir: "../cluster_output"

max_checkpoints: 10

model_name: 'microsoft/codebert-base'
learning_rate: 1e-5

finetune_mode: all

languages:
    - python

cuda_graphs: False

preprocess_cores: 10
preprocess_mode: concat

max_input_tokens: 256

optimizer: adam

precision: mixed

lr_schedule: linear
#schedule: constant
