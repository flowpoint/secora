hostname: localhost
    
port: 12355

num_gpus: 'auto'

name: 'local_1ep_full'

batch_size: 8
infer_batch_size: 8

seed: 42
epochs: 1
shards: 15

grad_accum: 64 # counted in batches

warmup_batches: 10000
temp: 0.05

embedding_size: 128
top_k:  5

logdir: "./output"
checkpoint_dir: "./output"

max_checkpoints: 20

cuda_graphs: False

model_name: 'microsoft/codebert-base'
learning_rate: 1e-5

finetune_mode: all

languages:
    - python


preprocess_cores: 10
preprocess_mode: concat

max_input_tokens: 256

optimizer: adam

precision: mixed

lr_schedule: constant
